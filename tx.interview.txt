（1）给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？
方案1：
可以估计每个文件的大小为5G×64=320G，远远大于内存限制的4G。所以不可能将其完全加载到内存中处理。考虑采取分而治之的方法。
遍历文件a，对每个url求hash(url)%1000，然后根据所取得的值将url分别存储到1000个小文件（记为a0,a1,a2...a999）中，这样每个小文件的大约为300M。
遍历文件b，采取和a相同的方式将url分别存储到1000小文件（记为b0,b1,b2...b999）中。这样处理后，所有可能相同的url都在对应(a0-b0,a1-b1,...,a999-b999)的小文件中，不对应的小文件不可能有相同的url。然后我们只要求出1000对小文件中相同的url即可。
求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。

方案2：      
如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后逐个读取另外一个文件的url，检查它是否在Bloom filter表示的集合中，如果是，那么该url应该是共同的url（注意会有一定的错误率）。
（2）在25亿个整数中找出不重复的整数，内存不足以容纳这25亿个整数。
方案1：
采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需232∗2bit=230B232∗2bit=230B=1GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所有整数遍历完成后，查看bitmap，把对应位是01的整数输出即可。


方案2：
采用映射的方法，比如模1000，把整个大文件映射为1000个小文件，再找出每个小文件中不重复的整数。对于每个小文件，用hash_map(int,count)来统计每个整数出现的次数，输出即可。
（3）1000万字符串，其中有些是重复的，需要把重复的全部去掉，保留没有重复的字符串。请怎么设计和实现？
方案1：这题用trie树比较合适，hash_map也应该能行。
   